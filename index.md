---
layout: homepage
---

## About Me

I am a second-year CS PhD student at University of California, Davis, advised by Prof. [Lifu Huang](https://wilburone.github.io/). My research centers on improving the reasoning, understanding, and interpretability of foundation models. Currently, I focus on  developing more efficient, adaptive, and controllable algorithms for foundation models to handle complex reasoning and self-training tasks, while systematically analyzing their limitations and failure modes. My goal is to make these models not only more capable, but also more trustworthy and transparent.

Prior to starting my PhD, I completed my MS in Operations Research at [Virginia Tech](https://www.ise.vt.edu/), and obtained my BS from [Sharif University of Technology](https://en.sharif.edu/). 

If you're interested in my research, would like to discuss relevant topics, or explore potential collaborations, please feel free to get in touch :) - I am best reached by email at [mbeigi@ucdavis.edu](mailto:mbeigi@ucdavis.edu).


## Research Interests

- **Reasoning and Self-Training of Large Language Models**
- **Mechanistic Interpretability of Foundation Models**
- **Uncertainty Estimation and Quantification**

## News
- **[Feb. 2025]** Our new survey on mechanistic interpretability for multi-modal foundation models is availble at [arxiv](https://arxiv.org/abs/2502.17516)!
- **[Jan. 2025]** Glad to share that our lab has moved to UC Davis!
- **[Oct. 2024]** Our new survey on uncertainty estimation and quantification of LLMs is availble at [arxiv](https://arxiv.org/abs/2410.20199)!
- **[Sept. 2024]** Our paper [InternalInspector](https://arxiv.org/abs/2406.12053) is accepted to [**EMNLP 2024**](https://2024.emnlp.org/)! 
- **[May. 2024]** Our paper [Navigating Dual Facet](https://arxiv.org/abs/2402.11122) on evaluating the memory editing of LLMs is accepted to [**ACL 2024**](https://2024.aclweb.org/)!

{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}
